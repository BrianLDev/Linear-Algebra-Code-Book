{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Matrix Inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- content: pp. 327 - 354\n",
    "- exercises: pp. 355 - 362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import commonly used python libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Concepts and applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reminder: matrix division doesn't exist per se, but you can perform a similar action by multiplying a matrix by its inverse.\n",
    "- not all numbers have inverses (i.e. you can't divide by 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix inverse concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The matrix inverse is a matrix that multiples another matrix such that the product is the identity matrix. This is because the identity matrix is the analog of the number 1.\n",
    "$$A^{-1}A=I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here is an example application of matrix inverse:\n",
    "$$Ax = b$$\n",
    "$$A^{-1}Ax = A^{-1}b$$\n",
    "$$Ix = A^{-1}b$$\n",
    "$$x = A^{-1}b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **IMPORTANT:** Because matrix multiplication is non-commutative (i.e. $AB \\neq BA$), you need to be mindful to multiply both sides of the equation by the matrix inverse on the same side.\n",
    "- e.g. the following equation is **WRONG**:\n",
    "$$A^{-1}Ax = bA^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverting the inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- because the inverse is unique, it can be undone / reversed.  Therefore:\n",
    "$$(A^{-1})^{-1} = A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose and inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inverting the inverse is remininiscent of double transposing a matrix ($A^{TT}=A$), but transpose and inverse are completely different operations.\n",
    "  - *note: there is actually a special kind of matrix called an orthogonal matrix for which the inverse equals the transpose (covered in next chapter) but for most cases they are not the same.*\n",
    "- That said, the inverse and transpose do have a special relationship where the transpose of the inverse equals the inverse of the transpose:\n",
    "$$(A^{-1})^T = (A^T)^{-1} = A^{-T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions for invertibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- just like not all numbers have an inverse, not all matrices have an inverse.\n",
    "- in fact, many (or perhaps most) matrices that you will work with in practical applications are not invertible.\n",
    "- *note: remember that square matrices without an inverse are called singular / reduced-rank, or rank-deficient.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix has a full inverse matrix if the following criteria are met:\n",
    "1. It is square\n",
    "2. It is full-rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what does a \"full\" matrix inverse mean? It means you can put the inverse on either side of the matrix and still get the identity matrix:\n",
    "  - thus, the full matrix inverse is one of the few exceptions to matrix multiplication commutitivity.\n",
    "$$AA^{-1} = A^{-1}A = I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some rectangular matrices have a \"one-sided\" inverse, if certain conditions are met.  One-sided inverses are non-commutative.\n",
    "- for example $AA^{-1} = I$ but $A^{-1}A \\neq I$\n",
    "- for this reason, the \"full inverse\" is also sometimes called the \"two-sided inverse\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to LIVE EVIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quick reminder:\n",
    "$$(ABC)^{-1} = C^{-1}B^{-1}A^{-1}$$\n",
    "- however this is not as simple as it sounds: it is possible for the matrix product (ABC) to be invertible while the individual matrices are not invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniqueness of the matrix inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every inverse is unique, meaning that **if a matrix has an inverse, it has exactly one inverse**\n",
    "- proof for this statement is provided on page 331-332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse of a symmetric matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The inverse of a symmetric matrix is itself symmetric.\n",
    "- i.e. if $A = A^T$ then $A^{-1} = A^{-T}$\n",
    "- proof provided on page 332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid the inverse when possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Important to note that the matrix inverse is great *in theory*.\n",
    "- When doing abstract paper-and-pencil work, you can invert matrices as much as you want, regardless of their size and content.\n",
    "- But in practice, computing the inverse of a matrix on a computer is difficult and can be wrought with numerical inaccuracies and rounding errors.\n",
    "- Thus, **in practical computer applications of linear algebra, you should avoid using the explicit inverse unless it is absolutely necessary!**\n",
    "- Computer scientists have worked hard to develop algorithms that solve problems that--on paper--require the inverse.  The details are beyond the scope of this book, but the fact that these algorithms are already provided allows you to focus on understanding the conceptual aspects of the inverse, while letting the computer deal with the number crunching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the matrix inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll cover 3 of the many algorithms to compute the matrix inverse in this book:\n",
    "  - MNA (minors, cofactors, adjugate)\n",
    "  - row-reduction\n",
    "  - SVD (Singular Value Decomposition)\n",
    "- the first 2 will be covered in this chapter, and SVD covered in chapter 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Inverse of a diagonal matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diagonal matrices have an extremely easy to compute inverse:\n",
    "- simply invert each diagonal element and ignore the off-diagonal zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "a & 0 & 0 \\\\\n",
    "0 & b & 0 \\\\\n",
    "0 & 0 & c\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "A^{-1} = \n",
    "\\begin{bmatrix}\n",
    "1/a & 0 & 0 \\\\\n",
    "0 & 1/b & 0 \\\\\n",
    "0 & 0 & 1/c\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "AA^{-1} = A^{-1}A = I = \n",
    "\\begin{bmatrix}\n",
    "a/a & 0 & 0 \\\\\n",
    "0 & b/b & 0 \\\\\n",
    "0 & 0 & c/c\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this shows one reason why singular matrices are not invertible:\n",
    "  - A singular diagonal matrix has at least one diagonal element equal to zero.\n",
    "  - if you try to apply the above shortcut, you'll end up with an element of 0/0.\n",
    "- unfortunately, calculating the matrix inverse for non-diagonal matrices is not nearly as easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Inverse of a 2x2 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The famous shortcut for computing the inverse of a 2x2 matrix has four steps:\n",
    "1. Compute the determinant and check whether $\\Delta = 0$.  (If the determinant is 0, then the matrix has no inverse.)\n",
    "2. Swap the diagonal elements.\n",
    "3. Multiply the off-diagonal elements by -1.\n",
    "4. Divide all matrix elements by $\\Delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the reason we start by computing the determinant is that the matrix has no inverse if the determinant is zero.\n",
    "- thus if step 1 gives you zero, you don't need to do anything else.\n",
    "- *reminder: the formula for calculating the determinant of a 2x2 matrix is ad-bc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of inverting a 2x2 matrix:**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{bmatrix}^{-1}\n",
    "= \\frac{1}{-1}\n",
    "\\begin{bmatrix}\n",
    "3 & -2 \\\\\n",
    "-2 & 1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-3 & 2 \\\\\n",
    "2 & -1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, multiplying the original by the calculated inverse will give you the identity matrix\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "-3 & 2 \\\\\n",
    "2 & -1\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "... and\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-3 & 2 \\\\\n",
    "2 & -1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General formula for the inverse of a 2x2 matrix:**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\frac{1}{ad-bc}\n",
    "\\begin{bmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example when we try to invert a rank 1 matrix:**\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 4\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\frac{1}{4-4}\n",
    "\\begin{bmatrix}\n",
    "4 & -2 \\\\\n",
    "-2 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "notice how 4-4 would require dividing by zero, which is why this does not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 The MCA algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the shortcut for the 2x2 matrix is just a special case of the MCA algorithm (minors, cofactors, adjugate)\n",
    "- the full procedure is not difficult but time consuming:\n",
    "  - **M:**  Compute the *minors matrix*, a matrix of determinants of submatrices.\n",
    "  - **C:**  Compute the *cofactors matrix*, the Hadamard multiplication of the minors matrix with an alternative grid of +1 and -1.\n",
    "  - **A:**  Compute the *adjugate matrix*, the transpose of the cofactors matrix, divided by the determinant.\n",
    "- *(technically it's 4 steps if you consider dividing by the determinant its own full step, but MCA sounds better than MCAD)*\n",
    "\n",
    "Let's go through each step in more detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minors Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The minors matrix is a matrix in which each element $m{_i,j}$ of the matrix is the determinant of the matrix excluding the ith row and the jth column.\n",
    "- Thus, for each element in the matrix, cross out that row and that column, and compute the determinant of the remaining matrix.\n",
    "- The determinant goes into the matrix element under consideration\n",
    "- *note: the minors matrix is the most time-consuming part of the MCA algorithm.  It's also the most tedious (and prone to errors). Don't rush through it*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easier to understand visually:\n",
    "\n",
    "<img src=\"img\\12\\minors_matrix.jpg\" alt=\"Minors matrix\" width=500>\n",
    "\n",
    "(figure 12.1 on page 337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of minors matrix:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "0 & 4 & 2 \\\\\n",
    "1 & 3 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "m_{1,1} = \n",
    "\\begin{bmatrix}\n",
    "2 & & \\\\\n",
    "& & \\\\\n",
    "& & \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "m_{1,2} = \n",
    "\\begin{bmatrix}\n",
    "& -2 & \\\\\n",
    "& & \\\\\n",
    "& & \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "M = \n",
    "\\begin{bmatrix}\n",
    "2 & -2 & -4 \\\\\n",
    "-1 & 3 & 5 \\\\\n",
    "-2 & 4 & 8\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cofactors Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cofactors matrix is the Haramard product of the minors matrix with a matrix of alternating signs.\n",
    "- let's call that matrix $G$ for grid:\n",
    "  - the matrix is a grid of +1's and -1's starting with +1 for the upper-left element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examples of G matrices:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "+ & - \\\\\n",
    "- & +\n",
    "\\end{bmatrix}\n",
    ",\n",
    "\\begin{bmatrix}\n",
    "+ & - & + \\\\\n",
    "- & + & - \\\\\n",
    "+ & - & +\n",
    "\\end{bmatrix}\n",
    ",\n",
    "\\begin{bmatrix}\n",
    "+ & - & + & - \\\\\n",
    "- & + & - & + \\\\\n",
    "+ & - & + & - \\\\\n",
    "- & + & - & +\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the formula that defines each element of the $G$ matrix is\n",
    "$$g_{i,j} = (-1)^{i+j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, the cofactors matrix:\n",
    "$$\n",
    "C = G \\odot M\n",
    "$$\n",
    "\n",
    "using the example matrix from the minors matrix section:\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "2 & 2 & -4 \\\\\n",
    "1 & 3 & -5 \\\\\n",
    "-2 & -4 & 8\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjugate matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- at this point, all the hard work is done\n",
    "- the adjugate matrix is simply the transpose of the cofactors matrix, scalar-multiplied by the inverse of the determinant of the matrix.\n",
    "- *note: its the determinant of the original matrix, not the minors or cofactors matrices)*\n",
    "- again, if the determinant is zero, then this step will fail because of division by zero\n",
    "- assuming the determinant is not zero, the adjugate matrix is the inverse of the original matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuing with the matrix used in previous examples...\n",
    "$$\n",
    "A^{-1} =\n",
    "\\frac{1}{2}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & -2 \\\\\n",
    "2 & 3 & -4 \\\\\n",
    "-4 & -5 & 8\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test that this matrix is really the inverse of the original matrix:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & 1 \\\\\n",
    "0 & 4 & 2 \\\\\n",
    "1 & 3 & 2\n",
    "\\end{bmatrix}\n",
    "\\frac{1}{2}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & -2 \\\\\n",
    "2 & 3 & -4 \\\\\n",
    "-4 & -5 & 8\n",
    "\\end{bmatrix}\n",
    " = \n",
    "\\frac{1}{2}\n",
    "\\begin{bmatrix}\n",
    "2 & 0 & 0 \\\\\n",
    "0 & 2 & 0 \\\\\n",
    "0 & 0 & 2\n",
    "\\end{bmatrix}\n",
    "= I\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate inverse in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  2.56414665e-15,  2.78209180e-15],\n",
       "       [ 1.12854838e-15,  1.00000000e+00,  2.85291731e-15],\n",
       "       [ 5.41044566e-17, -2.59892652e-16,  1.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate inverse using Python \n",
    "A = np.random.randn(3,3)\n",
    "Ai = np.linalg.inv(A)\n",
    "A@Ai  # equals identity matrix (note that the tiny off-diagonals round to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.66133815e-16, -1.77635684e-15,  1.11022302e-15],\n",
       "       [-4.44089210e-16, -4.44089210e-16,  9.15933995e-16],\n",
       "       [-4.02455846e-16,  3.33066907e-16,  1.66533454e-16]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show that the inverse of the inverse returns to A\n",
    "Ai_i = np.linalg.inv(Ai)\n",
    "A - Ai_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 Inverse via row reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is a conceptually very different method for obtaining the inverse of a square matrix, but the result will be the same.\n",
    "- the idea is to augment the matrix with the identity matrix and then perform row reduction to get the matrix into RREF form.\n",
    "- This will lead to 2 possible outcomes:\n",
    "  - row reduction transforms the original matrix into the identity matrix, in which case the augmented matrix is the inverse\n",
    "  - row reduction does not produce the identity matrix, in which case the matrix is singular and therefore has no inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row reduction method of computing the inverse**\n",
    "$$\n",
    "rref([A | I]) \\Rightarrow [I | A^{-1}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & | & 1 & 0 \\\\\n",
    "3 & 4 & | & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "-3R_1 + R_2 \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & | & 1 & 0 \\\\\n",
    "0 & -2 & | & -3 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "R_2 + R_1 \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & | & -2 & 1 \\\\\n",
    "0 & -2 & | & -3 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "-1/2 R_2 \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & | & -2 & 1 \\\\\n",
    "0 & 1 & | & 3/2 & -1/2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you can confirm that the augmented part of the final matrix is the same as the inverse we computerd from the MCA algorithm in the practice problems from the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the rref equation almost seems like magic\n",
    "- but the reason why this method works is fairly straightforward and involves thinking about the equation in terms of solving a system of equations.\n",
    "- In Ch 10, you learned you can solve $Ax=b$ by performing Gauss-Jordan elimination on the augmented matrix $[A|b]$\n",
    "- if there is a solution (i.e. if $b$ is in the column space of $A$) then row reduction produces the augmented matrix $[I|x]$\n",
    "- here we follow the same reasoning, but the vector $b$ is expanded to the matrix $I$.\n",
    "- that is, we want to solve $AX=I$, where $X$ is the inverse of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for inverse via row reduction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0.539951596379099 & -0.113115914004011 & 1.15152208739062\\\\0 & 1 & 0 & -1.17483562716614 & 0.602409073632126 & -0.965549288105806\\\\0 & 0 & 1 & -3.05080679475566 & -0.931962995135268 & -1.6479159805779\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 0, 0, 0.539951596379099, -0.113115914004011,   1.15152208739062],\n",
       "[0, 1, 0, -1.17483562716614,  0.602409073632126, -0.965549288105806],\n",
       "[0, 0, 1, -3.05080679475566, -0.931962995135268,   -1.6479159805779]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Code for inverse via row reduction method\n",
    "import sympy as sym\n",
    "A = np.random.randn(3,3)\n",
    "Acat = np.concatenate((A, np.eye(3,3)), axis=1)\n",
    "Ar = sym.Matrix(Acat).rref()[0]   # RREF of original matrix on left, inverse on right\n",
    "Ar  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.539951596379099 & -0.113115914004011 & 1.15152208739062\\\\-1.17483562716614 & 0.602409073632126 & -0.965549288105806\\\\-3.05080679475566 & -0.931962995135268 & -1.6479159805779\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[0.539951596379099, -0.113115914004011,   1.15152208739062],\n",
       "[-1.17483562716614,  0.602409073632126, -0.965549288105806],\n",
       "[-3.05080679475566, -0.931962995135268,   -1.6479159805779]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ar_inv = Ar[:, 3:]   # retain only the calculated inverse\n",
    "Ar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}-1.11022302462516 \\cdot 10^{-16} & -2.77555756156289 \\cdot 10^{-17} & 0\\\\0 & 0 & 1.11022302462516 \\cdot 10^{-16}\\\\-4.44089209850063 \\cdot 10^{-16} & 0 & -4.44089209850063 \\cdot 10^{-16}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[-1.11022302462516e-16, -2.77555756156289e-17,                     0],\n",
       "[                    0,                     0,  1.11022302462516e-16],\n",
       "[-4.44089209850063e-16,                     0, -4.44089209850063e-16]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_inv = np.linalg.inv(A)  # calculate inverse using alternative method done previously\n",
    "Ar_inv - A_inv            # demonstrate that they are equal (tiny numbers can be rounded to 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "The matrix inverse is a funny thing.  Conceptually, its one of the most important matrix operations in linear algebra and its applications.  And yet, computer programs go to great lengths to avoid explicitly computing it unless absolutely necessary.  So why, you might wonder, should I suffer through learning how to compute it when I can type `inv` on a computer?  For the same reason that you need to compute 3+4 without a calculator: you will never really learn math unless you can do it without a computer.  Frustrating but true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 Left inverse for tall matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As mentioned previously, only square matrices can have a full inverse.\n",
    "- That's true, but it applies only to a *full* aka two-sided inverse.\n",
    "- Rectangular matrices can have a 1-sided inverse, which we'll explore in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's start with a tall matrix, so dimensions M > N.\n",
    "- Well call the matrix $T$ for tall.\n",
    "- although this matrix is not invertible, we can come up with another matrix that will left-multiply $T$ to produce the identity matrix.\n",
    "- the key insight to get started is that $T^TT$ is a square matrix.\n",
    "- In fact, $T^TT$ is invertible if $rank(T)=N$ (more on this condition later)\n",
    "- if $T^TT$ is invertible, then it has an inverse:\n",
    "$$\n",
    "(T^TT)^{-1} T^T T = I\n",
    "$$\n",
    "- *note: the 1st parentheses are necessary because we ar einverting the product of two matrices, and neither of those matrices is individually invertible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could split this up by breaking out the left inverse...\n",
    "$$\n",
    "T^{-L} = (T^TT)^{-1} T^T\n",
    "$$\n",
    "which leads to...\n",
    "$$\n",
    "T^{-L} T = I\n",
    "$$\n",
    "(note that this is non-standard notation, just used here for clarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions for validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 conditions for a matrix to have a left inverse:\n",
    "1. it is tall (more rows than columns, M > N)\n",
    "2. It is full column rank (rank=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see example on page 348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Right inverse for wide matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as might be expected this is the corrolary to left inverse for tall matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The right inverse equation**\n",
    "$$\n",
    "W W^T (WW^T)^{-1} = I\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to above, we could split this up by breaking out the right inverse...\n",
    "$$\n",
    "W^{-R} = W^T(WW^T)^{-1}\n",
    "$$\n",
    "which leads to...\n",
    "$$\n",
    "W W^{-L} = I\n",
    "$$\n",
    "(note that this is non-standard notation, just used here for clarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 conditions for a matrix to have a left inverse:\n",
    "1. it is wide (more columns than rows, N > M)\n",
    "2. It is full row rank (rank=M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for left inverse of a tall matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -2.57092712e-18, -1.50484792e-18],\n",
       "       [ 8.58045018e-17,  1.00000000e+00, -7.42865204e-17],\n",
       "       [-1.09943088e-17,  1.80516171e-17,  1.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for left inverse of a tall matrix in Python\n",
    "A = np.random.randn(5, 3)\n",
    "Al = np.linalg.inv(A.T@A)@A.T\n",
    "Al@A  # should equal Identity matrix (round tiny off diagonals to zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8 The pseudoinverse, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is called \"part 1\" because the pseudoinverse is going to be introduced here, but not going to dive into its computation until 16.12 (SVD chapter)\n",
    "- The pseudoinverse is used when a matrix does not have a full inverse, e.g. if the matrix is square but rank-deficient.\n",
    "- as mentioned previously, a rank-deficient matrix does not have a true inverse, however **all matrices have a pseudoinverse, which is a matrix that will transform the rank-deficient matrix into something close to (but not quite) the identity matrix.**\n",
    "- there are several algorithms to compute a pseudoinverse, but the most commonly used method is called the Moore-Penrose pseudoinverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important concepts about the pseudoinverse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It is indicated using a \"dagger\", asterisk, or plus sign in the superscrpt: $A^\\dagger, A^* or A^+$\n",
    "  - *note: the dagger or asterisk superscript is typically used in physics to represent the Hermitian adjoint.  Are they related to the pseudoinverse?*\n",
    "2. The pseudoinverse multiplies the original matrix to approximate the identity matrix: $AA^\\dagger \\approx I$\n",
    "3. There are several ways to create a matrix pseudoinverse, which means that a singular matrix can have several pseudoinverses (unlike the true inverse, which is unique).  However, the MP pseudoinverse is unique, meaning that every matrix has exactly one MP pseudoinverse.  The uniqueness of the MP pseudoinverse contributes to its popularity.\n",
    "4. The pseudoinverse is sided, thus $AA^\\dagger \\neq A^\\dagger A$.  However, the pseudoinverse has the neat property that $A A^\\dagger A = A$ (for square matrices)\n",
    "5. For a full-rank matrix, the pseudoinverse is the same as the full inverse, that is, $A^\\dagger = A^{-1}$\n",
    "6. For a tall full column-rank matrix, the pseudoinverse equals the one-sided left inverse.  Same story for a wide full row-rank matrix and the right inverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see examples of the pseudoinverse on p. 353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for MP pseudoinverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for MP pseudoinverse\n",
    "A = np.random.randn(3,3)\n",
    "A[1, :] = A[0, :]         # copy a row so that the rank is reduced and the matrix is singular\n",
    "np.linalg.matrix_rank(A)  # rank should be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97914074,  0.05848156,  0.13039961],\n",
       "       [ 0.05848156,  0.8360396 , -0.36559171],\n",
       "       [ 0.13039961, -0.36559171,  0.18481966]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pinv = np.linalg.pinv(A)\n",
    "A_pinv@A  # should be roughly close to the Identity matrix (round tiny off diagonals to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.88165750e+15, -2.88165750e+15,  4.44136316e-01],\n",
       "       [-8.07908923e+15,  8.07908923e+15,  4.74555941e-01],\n",
       "       [-1.80143985e+16,  1.80143985e+16, -0.00000000e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.88178420e-16,  1.11022302e-16,  1.11022302e-16],\n",
       "       [-1.33226763e-15, -2.22044605e-16,  3.33066907e-16],\n",
       "       [-4.85722573e-16,  4.44089210e-16, -1.11022302e-16]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the pseudoinverse of the pseudoinverse returns back to A\n",
    "A_pinv_pinv = np.linalg.pinv(A_pinv)\n",
    "A - A_pinv_pinv   # it does. (note that tiny numbers can be rounded to 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9 - 12.10 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11 - 12.12 Code challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "656cd6254c7b2065e00f01cfa19c07ca066e7d85ef474593a41f6dcc31570de2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
